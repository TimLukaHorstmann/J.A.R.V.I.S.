# Application Settings
application:
  name: "Jarvis"
  log_level: "INFO"
  log_format: "%(asctime)s %(levelname)s %(name)s â”€ %(message)s"

# TTS Engine Configuration
tts:
  engine: "kokoro"
  kokoro:
    lang_code: "a"  # 'a' => American English
    voice: "am_liam"
    sample_rate: 24000

# ASR (Speech Recognition) Configuration
asr:
  engine: "whisper"
  whisper:
    model_size: "small"
    device: "cpu" # or "cuda", "mps"
    compute_type: "int8" # "float16" for GPU

# LLM (Language Model) Configuration
llm:
  base_url: "http://localhost:8000/v1"
  model_alias: "gpt-3.5-turbo" # This is just an alias for the local model
  
  # Recommended Models for Mac (Apple Silicon):
  # 1. Llama-3.2-3B-Instruct (Fast, Smart, Small) - BEST OVERALL
  #    repo_id: "bartowski/Llama-3.2-3B-Instruct-GGUF"
  #    filename: "Llama-3.2-3B-Instruct-Q4_K_M.gguf"
  #
  # 2. Qwen2.5-7B-Instruct (Smarter, Slower)
  #    repo_id: "bartowski/Qwen2.5-7B-Instruct-GGUF"
  #    filename: "Qwen2.5-7B-Instruct-Q4_K_M.gguf"
  
  # Current Selection:
  repo_id: "bartowski/mlabonne_Qwen3-4B-abliterated-GGUF"
  filename: "mlabonne_Qwen3-4B-abliterated-Q4_K_M.gguf"
  local_dir: "pretrained_models/llm"
  context_window: 8192 # 8k is a good balance for speed/memory on local devices

# MCP Configuration
mcp:
  servers:
    google_maps: 
      url: "http://127.0.0.1:4001/messages"
      transport: "sse"
    brave_search: 
      url: "http://127.0.0.1:4002/messages"
      transport: "sse"
    mcp-fetch: 
      url: "http://127.0.0.1:4003/messages"
      transport: "sse"
    weather: 
      url: "http://127.0.0.1:4004/messages"
      transport: "sse"
